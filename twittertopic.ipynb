{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW6DTGh4/IziX38VeRcTuJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmiekatana/Twitter--Topic-Sentiment--Analysis/blob/main/twittertopic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9CrBm_ehqXe"
      },
      "outputs": [],
      "source": [
        "#!pip install -q tweepy matplotlib wordcloud\n",
        "\n",
        "import tweepy\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping"
      ],
      "metadata": {
        "id": "iJFvldESiMWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Twitter API key and secret\n",
        "consumer_key = 'YOUR_CONSUMER_KEY'\n",
        "consumer_secret = 'YOUR_CONSUMER_SECRET'\n",
        "access_token = 'YOUR_ACCESS_TOKEN'\n",
        "access_token_secret = 'YOUR_ACCESS_TOKEN_SECRET'"
      ],
      "metadata": {
        "id": "osc569CpkGtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for handling pagination in our search and handle rate limits\n",
        "def limit_handled(cursor):\n",
        "    while True:\n",
        "        try:\n",
        "            yield cursor.next()\n",
        "        except tweepy.errors.TweepyException:\n",
        "            print (\"sleeping....\")\n",
        "            time.sleep(60 * 15)\n",
        "            continue\n",
        "        except StopIteration:\n",
        "            break\n",
        "\n",
        "# Define the term we will be using for searching tweets\n",
        "query = \"Snapdragon\"\n",
        "query = query + ' -filter:retweets'"
      ],
      "metadata": {
        "id": "CgV9A8O8kOmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define how many tweets to get from the Twitter API\n",
        "count = 18000\n",
        "\n",
        "# Search for tweets using Tweepy\n",
        "search = limit_handled(tweepy.Cursor(api.search_tweets,\n",
        "                        q=query,\n",
        "                        tweet_mode='extended',\n",
        "                        lang='en',\n",
        "                        result_type=\"recent\").items(count))"
      ],
      "metadata": {
        "id": "BqsNVxkqkT5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the results from the search using Tweepy\n",
        "tweets = []\n",
        "for result in search:\n",
        "    tweet_content = result.full_text\n",
        "    print(tweet_content)\n",
        "    # Only saving the tweet content.\n",
        "    # You could also save other attributes for each tweet like date or # of RTs.\n",
        "    tweets.append(tweet_content)"
      ],
      "metadata": {
        "id": "PE-27uvxkgLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TFqG_z5RkiBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis"
      ],
      "metadata": {
        "id": "K82coGg-kiDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the API call to the Inference API to do sentiment analysis\n",
        "model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "hf_token = \"YOUR_ACCESS_TOKEN\"\n",
        "API_URL = \"https://api-inference.huggingface.co/models/\" + model\n",
        "headers = {\"Authorization\": \"Bearer %s\" % (hf_token)}\n",
        "\n",
        "def analysis(data):\n",
        "    payload = dict(inputs=data, options=dict(wait_for_model=True))\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    return response.json()\n",
        "\n",
        "# Let's run the sentiment analysis on each tweet\n",
        "tweets_analysis = []\n",
        "for tweet in tweets:\n",
        "    try:\n",
        "        sentiment_result = analysis(tweet)[0]\n",
        "        top_sentiment = max(sentiment_result, key=lambda x: x['score']) # Get the sentiment with the higher score\n",
        "        tweets_analysis.append({'tweet': tweet, 'sentiment': top_sentiment['label']})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "        # Load the data in a dataframe\n",
        "pd.set_option('max_colwidth', None)\n",
        "pd.set_option('display.width', 3000)\n",
        "df = pd.DataFrame(tweets_analysis)\n",
        "\n",
        "# Show a tweet for each sentiment\n",
        "print(df[df[\"sentiment\"] == 'Positive'].head(1))\n",
        "print(df[df[\"sentiment\"] == 'Neutral'].head(1))\n",
        "print(df[df[\"sentiment\"] == 'Negative'].head(1))\n",
        "\n",
        "\n",
        "# Let's count the number of tweets by sentiments\n",
        "sentiment_counts = df.groupby(['sentiment']).size()\n",
        "print(sentiment_counts)\n",
        "\n",
        "# Let's visualize the sentiments\n",
        "fig = plt.figure(figsize=(6,6), dpi=100)\n",
        "ax = plt.subplot(111)\n",
        "sentiment_counts.plot.pie(ax=ax, autopct='%1.1f%%', startangle=270, fontsize=12, label=\"\")\n",
        "\n",
        "# Wordcloud with positive tweets\n",
        "positive_tweets = df['tweet'][df[\"sentiment\"] == 'Positive']\n",
        "stop_words = [\"https\", \"co\", \"RT\"] + list(STOPWORDS)\n",
        "positive_wordcloud = WordCloud(max_font_size=50, max_words=50, background_color=\"white\", stopwords = stop_words).generate(str(positive_tweets))\n",
        "plt.figure()\n",
        "plt.title(\"Positive Tweets - Wordcloud\")\n",
        "plt.imshow(positive_wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Wordcloud with negative tweets\n",
        "negative_tweets = df['tweet'][df[\"sentiment\"] == 'Negative']\n",
        "stop_words = [\"https\", \"co\", \"RT\"] + list(STOPWORDS)\n",
        "negative_wordcloud = WordCloud(max_font_size=50, max_words=50, background_color=\"white\", stopwords = stop_words).generate(str(negative_tweets))\n",
        "plt.figure()\n",
        "plt.title(\"Negative Tweets - Wordcloud\")\n",
        "plt.imshow(negative_wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "pd.DataFrame(tweets).to_csv(r\"SnapdragonRawData20220604.csv\")"
      ],
      "metadata": {
        "id": "v_j-F4qjkmiy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}